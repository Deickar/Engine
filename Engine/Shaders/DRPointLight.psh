cbuffer LightBufferType
{
	float4 LightPosition;
	float4 LightColor; //.w channel contains LightRadius
	//float LightRadius;
	float4 CameraPosition; //.w channel contains LightPower
	//float LightPower;
}

cbuffer PixelMatrixBufferType
{
	float4x4 InvertedView;
	float4x4 InvertedProjection;
}

struct VertexShaderOutput
{
	float4 Position : SV_Position;
	float4 ScreenPosition : TEXCOORD0;
	float4 ViewPosition : TEXCOORD1;
	float3 ViewRay : TEXCOORD2;
};

Texture1DArray materialArray;
Texture2D textures[3]; //Color, Normal, depth. In that order
SamplerState pointSampler;

static const float CameraFarClip = 400.0f;

//////////////////////////////////////////////////
//	FUNCTIONS
//////////////////////////////////////////////////

//Decoding of GBuffer Normals
float3 DecodeNormal(float2 enc)
{
	float2 fenc = (enc*4.0f)-2.0f;
	float f = dot(fenc,fenc);
	float g = sqrt(1.0f-(f*0.25f));
	
	//float3 n;
	//n.xy = fenc*g;
	//n.z = 1.0f-(f*0.5f);

	return float3(fenc*g, 1.0f - (f*0.5f));
}

void RetrieveMaterialData(int materialID, out float Kd, out float Ks, out float surfaceSmoothness)
{
	/*
	Because the runtime does not support 1D textures, the compiler will use a 2D texture with the knowledge 
	that the y-coordinate is unimportant. Since tex1D(s, t) (DirectX HLSL) is implemented as a 2D texture lookup, 
	the compiler is free to choose the y-component in an efficient manner.
	*/

	int3 LoadingCoordinates = int3(0, materialID, 0);

	//Load all of the objects and assign them to local variables
	LoadingCoordinates.x += 1;

	Kd = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	Ks = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	surfaceSmoothness = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

}

float3 ReconstructViewPositionFromDepth(float3 viewPosition, float depth)
{
	float3 viewRay = float3(viewPosition.xy * (CameraFarClip / viewPosition.z), CameraFarClip);
	return viewRay * depth;
}

float3 ReconstructWorldPositionFromDepth(float3 viewRay, float depth)
{
	return CameraPosition.xyz + (viewRay * (depth*400.0f));
}

float3 DepthToPosition(float depth, float farClip, float4 ScreenPosition)
{
	float3 viewPosition = mul(ScreenPosition, InvertedProjection).xyz;
	float3 viewRay = float3(viewPosition.xy * (farClip / viewPosition.z), farClip);
	return viewRay * depth;
}

static const float cutoff = 2.0f;

///////////////////////////////////////////////////
//	MAIN FUNCTION
///////////////////////////////////////////////////
half4 LightPixelShader(VertexShaderOutput input) : SV_TARGET0
{
	float diffuseCoefficient, specularCoefficient, surfaceSmoothness;

	input.ScreenPosition /= input.ScreenPosition.w; //Get screen position

	float2 texCoord = 0.5f * (float2(input.ScreenPosition.x, -input.ScreenPosition.y) + 1.0f);

	float3 viewRay = normalize(input.ViewRay);

	//get normal data from the normalMap
	float4 normalData = textures[1].Sample(pointSampler, texCoord);

	int materialID = round(normalData.z * 255);
	int materialID2 = round(normalData.w * 255);

	RetrieveMaterialData(materialID, diffuseCoefficient, specularCoefficient, surfaceSmoothness);
	
	//If there's a difference between our two materials, we have to lerp!
	if(materialID != materialID2) 
	{
		float lerpVal = (textures[0].Sample(pointSampler, texCoord).w);
		float diffuseCoefficient2, specularCoefficient2, surfaceSmoothness2;

		RetrieveMaterialData(materialID2, diffuseCoefficient2, specularCoefficient2, surfaceSmoothness2);

		diffuseCoefficient = lerp(diffuseCoefficient, diffuseCoefficient2, lerpVal);
		specularCoefficient = lerp(specularCoefficient, specularCoefficient2, lerpVal);
		surfaceSmoothness = lerp(surfaceSmoothness, surfaceSmoothness2, lerpVal);
	}

	float depth = textures[2].Sample(pointSampler, texCoord);
	float3 normal = normalize(DecodeNormal(normalData.xy));
	
	float4 position = float4(ReconstructWorldPositionFromDepth(input.ViewRay, depth), 1.0f);//mul(float4(ReconstructViewPositionFromDepth(input.ViewPosition.xyz, depth), 1.0f), InvertedView);//float4(ReconstructWorldPositionFromDepth(viewRay, depth), 1.0f); //ReconstructPositionFromDepth(depth, input.ScreenPosition.xy);

	//surface-to-light vector
	float3 lightVector = (position - LightPosition);

	float d = length(lightVector);
	float denom = ((d*d) / LightColor.w);
	float attenuation = min((CameraPosition.w - cutoff) / (denom*denom), 1.0f); //((LightColor.w) / (d*d)); //(LightColor.w / (d*d)); //Slight offset to dampen the light

	//Normalize lightVector after we've used it to determine the light attenuation
	lightVector = normalize(lightVector);

	////calculate NdotL product
	//float NdL = max(abs(dot(normal, -lightVector)), 0.1f);

	//compute diffuse light using NdotL product
	float3 diffuseLight = LightColor.rgb;//max((LightColor.rgb*NdL), 0.1f);

	////Blinn half angle modification for performance over correctness
	//float3 h = normalize(normalize(CameraPosition - position) - lightVector);

	////compute specular light
	//float specularLight = pow( saturate( dot(h, normal)), surfaceSmoothness);

	 //reflection vector
	float3 reflectionVector = normalize(reflect(lightVector, normal));

	//camera-to-surface vector
	float3 directionToCamera = normalize(CameraPosition - position);

	//compute specular light. Phong.
	float specularLight = pow(saturate(dot(reflectionVector, directionToCamera)), surfaceSmoothness);

	//scale final value with attenuation, take into calculation the current material of this pixel
	return half4((diffuseCoefficient*diffuseLight), (specularCoefficient*specularLight)) * attenuation;
}