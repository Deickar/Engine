/////////////////////////////////////////////
//////////////////INPUT//////////////////////
/////////////////////////////////////////////

cbuffer PositionalBuffer //Whatever, idk what else to name it
{
	float3 LightDirection;
	float3 LightPosition;
	float3 CameraPosition;
	float3 Padding;
};

cbuffer PixelMatrixBuffer
{
	float4x4 InverseView;
	float4x4 InverseViewProjection;
	float4x4 LightViewProjection;
};

cbuffer LightBuffer
{
	float4 DiffuseColor;
	float4 AmbientColor;
	float Ka;
	//Ambient light coefficient
	float Kd;
	//Diffuse light coefficient
	float Ks;
	//Specular light coefficient
	float a;
	//Alpha coefficient
};

//0 == linear, 1 == point
//SamplerState samplers[2];

SamplerState linearSampler : register(s0);
SamplerState anisotropicSampler : register(s1);

Texture2D shaderTextures[3]; // 0 = normal, 1 = standard depth, 2 = shadowmap depth.

struct VertexShaderOutput
{
	float4 Position : SV_POSITION;
	float2 TexCoord : TEXCOORD0;
	float4 ViewPosition : TEXCOORD1;
	float4 ScreenPosition : TEXCOORD2;
	float4 WorldPosition : TEXCOORD3;
};

/////////////////////////////////////////////
////////////UTILITY FUNCTIONS////////////////
/////////////////////////////////////////////

//Decoding of GBuffer Normals
float3 Decode(float3 enc)
{
	return (2.0f * enc.xyz - 1.0f);
}


float2 GetShadowTexOffset( int u, int v )
{
	//This has to mirror shadowmap render target width and height; I'm just really, really lazy.
	float2 shadowMapSize = float2(2048.0f, 2048.0f);	

	//Scale and return texture coordinates
	return float2( u * 1.0f/shadowMapSize.x, v * 1.0f/shadowMapSize.y );
}

//Not much to say, really
float Linstep(float minVal, float maxVal, float value)  
{
	return clamp( ((value - minVal) / (maxVal - minVal)), 0, 1);
}

float ReduceLightBleeding(float p_max, float amount)  
{
	// Remove the [0, Amount] tail and linearly rescale (Amount, 1].  
   return Linstep(amount, 1, p_max);
}
  
//Calculate shadow contribution using chevyshev's inequality.
float ChebyshevUpperBound(float2 moments, float t)  
{
	float minVariance = 0.0002f; //Scaling value.

	// Compute variance.  
	float variance = moments.y - (moments.x*moments.x);
	variance = max(variance, minVariance);

	// Compute probabilistic upper bound.  
	float d = t - moments.x;
	float p_max = variance / (variance + d*d);

	return p_max;
}
 

float ShadowContribution(float2 lightTexCoord, float distanceToLight)  
{
	// Read the moments from the variance shadow map.  
	float2 moments = shaderTextures[2].Sample(anisotropicSampler, lightTexCoord).rg;

	//If surface is fully lit, break early.
	if(distanceToLight <= moments.x)
	{
		return 1.0f;
	}

	// Compute the Chebyshev upper bound.
	float shadowContribution = ChebyshevUpperBound(moments, distanceToLight);

	shadowContribution = ReduceLightBleeding(shadowContribution, distanceToLight);

	return shadowContribution;
}


/////////////////////////////////////////////
///////////////MAIN FUNCTION/////////////////
/////////////////////////////////////////////

half4 LightPixelShader(VertexShaderOutput input) : SV_Target
{
	//I pre-declare all values so that I can still return the same variables if we break because we're outside of light frustum. It's neater this way.
	half4 finalAmbienceProduct = half4(0.0f, 0.0f, 0.0f, 0.0f);
	half4 finalDiffuseProduct = half4(0.0f, 0.0f, 0.0f, 0.0f);
	float finalSpecularProduct = 0.0f;

	//Sample camera depth
	float depth = shaderTextures[1].Sample(linearSampler, input.TexCoord);

	//Skip as early as possible if this pixel isn't supposed to be lit.
	if(0 >= depth) 
	{
		//0, 0, 0, 0
		return finalAmbienceProduct;	
	}

	finalAmbienceProduct += Ka * AmbientColor;
	float4 encodedNormal = shaderTextures[0].Sample(linearSampler, input.TexCoord);
	float3 normal = normalize(Decode(encodedNormal.xyz));
	
	//Adjust value
	input.ScreenPosition /= input.ScreenPosition.w;
	
	//Reconstructing position
	float4 position;
	position.xy = input.ScreenPosition.xy;

	//Add camera depth
	position.z = depth;

	//Set .w to 1.0f for later matrix multiplications
	position.w = 1.0f;

	//Extract pixel world position as seen from camera POV.
	position = mul(position, InverseViewProjection);

	//Adjust value
	position /= position.w;

	//Extract pixel position as seen from light POV for shadow map extraction.
	float4 lightScreenPos = mul(position, LightViewProjection);

	//Adjust value again.
	lightScreenPos /= lightScreenPos.w;

	//Depth as seen from camera POV.
	float realDistanceToLight = lightScreenPos.z;

	float2 sampleLightScreen;
	sampleLightScreen.x = ((lightScreenPos.x * 0.5f) + 0.5f);
	sampleLightScreen.y = ((-lightScreenPos.y * 0.5f) + 0.5f);

	float shadowMultiplier = 1.0f;

	//We cull a large part of the light and shadow calculations if it's outside of the light frustum.
	if
	(		
		!(	sampleLightScreen.x > 1 || sampleLightScreen.x	< 0	|| 
			sampleLightScreen.y > 1 || sampleLightScreen.y	< 0	|| 
			lightScreenPos.z	> 1 || lightScreenPos.z		< 0		)
	)
	{
		float sum = 0.0f;
		float x, y;
		//TODO: variance shadow mapping... http://http.developer.nvidia.com/GPUGems3/gpugems3_ch08.html

		//realDistanceToLight -= 0.0002f; //Apply shadow bias	

		shadowMultiplier = ShadowContribution(sampleLightScreen, realDistanceToLight);
		
		//perform PCF filtering on a 4 x 4 texel neighborhood
		//for (y = -1.5f; y <= 1.5f; y += 1.0f)
		//{
		//	for (x = -1.5f; x <= 1.5f; x += 1.0f)
		//	{
		//		sum += shaderTextures[2].SampleCmpLevelZero(cmpSampler, sampleLightScreen + GetShadowTexOffset(x,y), realDistanceToLight);
		//	}
		//}

		//shadowMultiplier = (sum / 16.0f);

		////Use this instead for normal unfiltered shadows. Produces more artifacts. Nasty.

		//float distanceStoredInDepthMap = shaderTextures[2].Sample(linearSampler, sampleLightScreen);

		//if (realDistanceToLight < 1.0f && realDistanceToLight > distanceStoredInDepthMap)
		//{
		//	shadowMultiplier = 0.35f;
		//}
		
		//Surface-to-light vector
		float3 lightVector = (-LightDirection);

		//Calculate diffuse intensity, the usual
		float NdL = (max(0, dot(normal, lightVector)));

		//Reflection vector
		float3 reflectionVector = normalize(-reflect(lightVector, normal));

		//Camera-to-surface vector
		float3 directionToCamera = normalize(position-CameraPosition);

		//Calculate diffuse light
		finalDiffuseProduct.xyzw += Kd * NdL;

		//Calculate specular light 
		finalSpecularProduct += Ks * pow( saturate(dot(directionToCamera, reflectionVector)), a);
	}


	//Storing specular in alpha channel. Applying shadow multiplier to both diffuse product and specular, but not ambient, to make sure it's not completely black in shaded places.
	return half4(finalAmbienceProduct.rgb + shadowMultiplier * (DiffuseColor.rgb*finalDiffuseProduct.rgb), shadowMultiplier * finalSpecularProduct);
}
