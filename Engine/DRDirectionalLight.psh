/////////////////////////////////////////////
//////////////////INPUT//////////////////////
/////////////////////////////////////////////

cbuffer PositionalBuffer //Whatever, idk what else to name it
{
	float4 LightDirection;
	float4 LightPosition;
	float4 CameraPosition;
};

cbuffer PixelMatrixBuffer
{
	float4x4 InverseViewProjection;
	float4x4 LightViewProjection;
};

cbuffer LightBuffer
{
	float4 DiffuseColor;
	float4 AmbientColor;
};

SamplerState linearSampler : register(s0);
SamplerState anisotropicSampler : register(s1);
SamplerComparisonState cmpSampler : register(s2);

Texture1DArray materialArray;
Texture2D shaderTextures[3]; // 0 = normal, 1 = standard depth, 2 = shadowmap depth.

struct VertexShaderOutput
{
	float4 Position : SV_POSITION;
	float2 TexCoord : TEXCOORD0;
	float4 ScreenPosition : TEXCOORD1;
};

/////////////////////////////////////////////
////////////UTILITY FUNCTIONS////////////////
/////////////////////////////////////////////
void RetrieveMaterialData(int materialID, out float ambienceCoefficient, out float diffuseCoefficient, 
	out float specularCoefficient, out float surfaceSmoothness, out bool recieveShadows)
{
	/*
	Because the runtime does not support 1D textures, the compiler will use a 2D texture with the knowledge 
	that the y-coordinate is unimportant. Since tex1D(s, t) (DirectX HLSL) is implemented as a 2D texture lookup, 
	the compiler is free to choose the y-component in an efficient manner.
	*/

	int3 LoadingCoordinates = int3(0, materialID, 0);

	//Load all of the objects and assign them to local variables
	ambienceCoefficient = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	diffuseCoefficient = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	specularCoefficient = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	surfaceSmoothness = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	recieveShadows = ((materialArray.Load(LoadingCoordinates)) >= 0.01f ? true : false);
	LoadingCoordinates.x += 1;
}

//Decoding of GBuffer Normals
float3 DecodeNormal(float3 enc)
{
	return ((2.0f * enc.xyz) - 1.0f);
}

//Linear stepping function used when reducing light bleeding for variance shadowmaps
float Linstep(float minVal, float maxVal, float value)  
{
	return clamp( ((value - minVal) / (maxVal - minVal)), 0, 1);
}

float ReduceLightBleeding(float p_max, float amount)  
{
	// Remove the [0, Amount] tail and linearly rescale (Amount, 1].  
   return Linstep(amount, 1, p_max);
}
  
//Calculate shadow contribution using chevyshev's inequality.
float ChebyshevUpperBound(float2 moments, float t)  
{
	float minVariance = 0.002f; //Scaling value.

	// Compute variance.  
	float variance = moments.y - (moments.x*moments.x);
	variance = max(variance, minVariance);

	// Compute probabilistic upper bound.  
	float d = (t - moments.x);
	float p_max = (variance / (variance + d*d));

	return p_max;
}


float ShadowContribution(float2 lightTexCoord, float distanceToLight)  
{
	// Read the moments from the variance shadow map.  
	float2 moments = shaderTextures[2].Sample(anisotropicSampler, lightTexCoord);

	//If surface is fully lit, break early.
	if(distanceToLight <= moments.x)
	{
		return 1.0f;
	}

	// Compute the Chebyshev upper bound.
	float shadowContribution = ChebyshevUpperBound(moments, distanceToLight);

	//shadowContribution = ReduceLightBleeding(shadowContribution, distanceToLight);

	return shadowContribution;
}


/////////////////////////////////////////////
///////////////MAIN FUNCTION/////////////////
/////////////////////////////////////////////

float4 LightPixelShader(VertexShaderOutput input) : SV_Target
{
	float ambienceCoefficient, diffuseCoefficient, specularCoefficient, surfaceSmoothness;
	bool recieveShadows;

	//I pre-declare all values so that I can still return the same variables if we break before light calculations. 
	//It's neater this way.
	float4 finalAmbienceProduct = float4(0.0f, 0.0f, 0.0f, 0.0f);
	float3 finalDiffuseProduct = float3(0.0f, 0.0f, 0.0f);
	float finalSpecularProduct = 0.0f;

	float LightIntensity = LightPosition.w;

	//Sample camera depth
	float depth = shaderTextures[1].Sample(anisotropicSampler, input.TexCoord);

	if(depth <= 0.01f)
	{
		return finalAmbienceProduct; //0 0 0 0. We break really early for optimization + sky sphere
	}



	float4 encodedNormal = shaderTextures[0].Sample(anisotropicSampler, input.TexCoord);
	
	//http://gamedev.stackexchange.com/questions/22864/enconding-decoding-bit-value-in-texture-alpha-channel
	//We recreate the material ID
	int materialID = round(encodedNormal.w * 255);
	
	RetrieveMaterialData(materialID, ambienceCoefficient, diffuseCoefficient, specularCoefficient, surfaceSmoothness, recieveShadows);
	
	finalAmbienceProduct += ambienceCoefficient * AmbientColor;

	float3 normal = normalize(DecodeNormal(encodedNormal.xyz));

	//Surface-to-light vector
	float3 lightVector = (-LightDirection);

	//Calculate diffuse intensity, the usual
	float NdL = dot(lightVector, normal);

	//Adjust value
	input.ScreenPosition /= input.ScreenPosition.w;
	
	//Reconstructing position
	float4 position;
	position.xy = input.ScreenPosition.xy;
	position.z = depth;
	position.w = 1.0f;

	//Extract pixel world position as seen from camera POV.
	position = mul(position, InverseViewProjection);

	//Adjust value
	position /= position.w;

	//Extract pixel position as seen from light POV for shadow map extraction.
	float4 lightScreenPos = mul(position, LightViewProjection);

	//Adjust this value too.
	lightScreenPos /= lightScreenPos.w;

	float realDistanceToLight = lightScreenPos.z-0.00001f;

	float2 sampleLightScreen;
	sampleLightScreen.x = ((lightScreenPos.x * 0.5f) + 0.5f);
	sampleLightScreen.y = ((-lightScreenPos.y * 0.5f) + 0.5f);

	float shadowMultiplier = 1.0f;

	//We cull a large part of the light and shadow calculations if it's outside of the light frustum.
	if
	(		
		!(	sampleLightScreen.x > 1 || sampleLightScreen.x	< 0	|| 
			sampleLightScreen.y > 1 || sampleLightScreen.y	< 0	)
		&& NdL > 0.0f
	)
	{
		/*Variance shadow mapping. http://http.developer.nvidia.com/GPUGems3/gpugems3_ch08.html */
		shadowMultiplier = ShadowContribution(sampleLightScreen, realDistanceToLight);

		//Reflection vector
		float3 reflectionVector = normalize(reflect(lightVector, normal));

		//Camera-to-surface vector
		float3 directionToCamera = normalize(position - CameraPosition);

		//Calculate diffuse light
		finalDiffuseProduct += diffuseCoefficient * (NdL * DiffuseColor.rgb);

		//Calculate specular light 
		finalSpecularProduct += specularCoefficient * pow( saturate( dot(reflectionVector, directionToCamera)), surfaceSmoothness);
	}

	//Essentially I save a float in the normal render target's .w channel that decides if the object should be shaded or not.
	//I do this because of how the vegatation quads are built -- they each consist of three different quads, and they all shade eachother.
	//This results in the quads looking really ass and they start flickering when the light moves and shit. Bad.
	if(recieveShadows)
	{
		return LightIntensity*float4(finalAmbienceProduct.rgb + (finalDiffuseProduct * shadowMultiplier), (finalSpecularProduct * shadowMultiplier));
	}
	else //Don't shade if it shouldn't recieve any shadows. This also includes the empty space where nothing exists, seeing as we clear the normal rendertarget alpha channel to 0.0f in gbuffer stage.
	{
		return LightIntensity*float4(finalAmbienceProduct.rgb + finalDiffuseProduct, finalSpecularProduct);
	}
}
