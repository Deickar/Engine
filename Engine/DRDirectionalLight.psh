/////////////////////////////////////////////
//////////////////INPUT//////////////////////
/////////////////////////////////////////////

cbuffer PositionalBuffer //Whatever, idk what else to name it
{
	float4 LightDirection;
	float4 LightPosition;
	float4 CameraPosition;
	float4 ViewDirection;
};

cbuffer PixelMatrixBuffer
{
	float4x4 InverseViewProjection;
	float4x4 LightViewProjection;
};

cbuffer LightBuffer
{
	float4 DiffuseColor;
	float4 AmbientColor;
};

SamplerState linearSampler : register(s0);
SamplerState anisotropicSampler : register(s1);
SamplerComparisonState cmpSampler : register(s2);

Texture1DArray materialArray;
Texture2D shaderTextures[4]; // 0 = normal, 1 = standard depth, 2 = shadowmap depth, 3 = color map.

struct VertexShaderOutput
{
	float4 Position : SV_POSITION;
	float2 TexCoord : TEXCOORD0;
	float3 ViewPosition : TEXCOORD1;
};

/////////////////////////////////////////////
////////////UTILITY FUNCTIONS////////////////
/////////////////////////////////////////////
void RetrieveMaterialData(int materialID, out float ambienceCoefficient, out float diffuseCoefficient, 
	out float specularCoefficient, out float surfaceSmoothness, out bool recieveShadows)
{
	/*
	Because the runtime does not support 1D textures, the compiler will use a 2D texture with the knowledge 
	that the y-coordinate is unimportant. Since tex1D(s, t) (DirectX HLSL) is implemented as a 2D texture lookup, 
	the compiler is free to choose the y-component in an efficient manner.
	*/

	int3 LoadingCoordinates = int3(0, materialID, 0);

	//Load all of the objects and assign them to local variables
	ambienceCoefficient = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	diffuseCoefficient = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	specularCoefficient = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	surfaceSmoothness = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	//Kind of a crude way to store a bool, but it works.
	recieveShadows = ((materialArray.Load(LoadingCoordinates)) >= 0.5f ? true : false);
	LoadingCoordinates.x += 1;
}

//Decoding of GBuffer Normals
half3 DecodeNormal(half2 enc)
{
	half2 fenc = (enc*4.0f)-2.0f;
	half f = dot(fenc,fenc);
	half g = sqrt(1.0f-(f*0.25f));
	
	half3 n;
	n.xy = fenc*g;
	n.z = 1.0f-(f*0.5f);

	return n;
}

float4 ReconstructPositionFromDepth(float3 viewPosition, float2 texCoord)
{
	float3 viewRay = float3(viewPosition.xy * (150.0f / viewPosition.z), 150.0f);
	
	// Sample the depth and scale the view ray to reconstruct view space position
	float normalizedDepth = shaderTextures[1].Sample(linearSampler, texCoord);

	return float4(viewRay * normalizedDepth, 1.0f); //float4 positionVS =
}

//Linear stepping function used when reducing light bleeding for variance shadowmaps
float Linstep(float minVal, float maxVal, float value)  
{
	return clamp( ((value - minVal) / (maxVal - minVal)), 0, 1);
}

float ReduceLightBleeding(float p_max, float amount)  
{
	// Remove the [0, Amount] tail and linearly rescale (Amount, 1].  
   return Linstep(amount, 1, p_max);
}
  
//Calculate shadow contribution using chevyshev's inequality.
float ChebyshevUpperBound(float2 moments, float t)  
{
	float minVariance = 0.02f; //Scaling value.

	// Compute variance.  
	float variance = moments.y - (moments.x*moments.x);
	variance = max(variance, minVariance);

	// Compute probabilistic upper bound.  
	float d = (t - moments.x);
	float p_max = (variance / (variance + d*d));

	return pow(p_max, 8);
}


float ShadowContribution(float2 lightTexCoord, float distanceToLight)  
{
	// Read the moments from the variance shadow map.  
	float2 moments = shaderTextures[2].Sample(anisotropicSampler, lightTexCoord).rg;

	//If surface is fully lit, break early.
	if(distanceToLight < moments.x)
	{
		return 1.0f;
	}

	// Compute the Chebyshev upper bound.
	float shadowContribution = ChebyshevUpperBound(moments, distanceToLight);

	//shadowContribution = ReduceLightBleeding(shadowContribution, distanceToLight);

	return shadowContribution;
}


/////////////////////////////////////////////
///////////////MAIN FUNCTION/////////////////
/////////////////////////////////////////////

float4 LightPixelShader(VertexShaderOutput input) : SV_Target
{
	//http://gamedev.stackexchange.com/questions/29447/could-someone-explain-why-my-world-reconstructed-from-depth-position-is-incorrec

	//I pre-declare all values so that I can still return the same variables if we break before light calculations. 
	//It's neater this way.
	float4 finalAmbienceProduct = float4(0.0f, 0.0f, 0.0f, 0.0f);

	//Sample camera depth
	float depth = shaderTextures[1].Sample(linearSampler, input.TexCoord);

	if(depth <= 0.0f)
	{
		return finalAmbienceProduct; //0 0 0 0. We break really early for optimization + sky sphere
	}
	
	float ambienceCoefficient, diffuseCoefficient, specularCoefficient, surfaceSmoothness;
	bool recieveShadows = false; //Used to combat self-shadowing.
	float3 finalDiffuseProduct = float3(0.0f, 0.0f, 0.0f);
	float finalSpecularProduct = 0.0f;
	float LightIntensity = LightPosition.w;

	float4 encodedNormal = shaderTextures[0].Sample(anisotropicSampler, input.TexCoord);
	
	//http://gamedev.stackexchange.com/questions/22864/enconding-decoding-bit-value-in-texture-alpha-channel
	//We recreate the material IDs
	int materialID = round(encodedNormal.z * 255);
	int materialID2 = round(encodedNormal.w * 255);

	RetrieveMaterialData(materialID, ambienceCoefficient, diffuseCoefficient, specularCoefficient, surfaceSmoothness, recieveShadows);
	
	//If there's a difference between our two materials, we have to lerp!
	if(materialID != materialID2) 
	{
		float lerpVal = (shaderTextures[3].Sample(linearSampler, input.TexCoord).w);
		float ambienceCoefficient2, diffuseCoefficient2, specularCoefficient2, surfaceSmoothness2;

		RetrieveMaterialData(materialID2, ambienceCoefficient2, diffuseCoefficient2, specularCoefficient2, surfaceSmoothness2, recieveShadows);

		ambienceCoefficient = lerp(ambienceCoefficient, ambienceCoefficient2, lerpVal);
		diffuseCoefficient = lerp(diffuseCoefficient, diffuseCoefficient2, lerpVal);
		specularCoefficient = lerp(specularCoefficient, specularCoefficient2, lerpVal);
		surfaceSmoothness = lerp(surfaceSmoothness, surfaceSmoothness2, lerpVal);
	}

	finalAmbienceProduct += ambienceCoefficient * AmbientColor;

	float3 normal = normalize(DecodeNormal(encodedNormal.xy));

	//Surface-to-light vector
	float3 lightVector = (-LightDirection);

	//Calculate diffuse intensity, the usual
	float NdL = dot(lightVector, normal);

	float UpDotL = dot(lightVector, float3(0.0f, 1.0f, 0.0f));

	//Reconstructing position
	float4 position = ReconstructPositionFromDepth(input.ViewPosition, input.TexCoord);

	//Extract pixel position as seen from light POV for shadow map extraction.
	float4 lightScreenPos = mul(position, LightViewProjection);

	//Adjust this value too.
	lightScreenPos /= lightScreenPos.w;

	float realDistanceToLight = lightScreenPos.z;

	float2 sampleLightScreen;
	
	//Adjust from [-1,1] range to [0,1] range
	sampleLightScreen.x = ((lightScreenPos.x * 0.5f) + 0.5f);
	sampleLightScreen.y = ((-lightScreenPos.y * 0.5f) + 0.5f);

	float shadowMultiplier = 1.0f;

	//We cull a large part of the light and shadow calculations if it's outside of the light frustum.
	//Using 0.99 and 0.01 because if I use 1.0 and 0.0, I get black lines along the extreme edge of the light frustum
	if
	(		
		!(	sampleLightScreen.x >= 0.99f || sampleLightScreen.x	<= 0.01f	|| 
			sampleLightScreen.y >= 0.99f || sampleLightScreen.y	<= 0.01f	||
			realDistanceToLight >= 0.99f || realDistanceToLight <= 0.01f		)
	)
	{
		/*Variance shadow mapping. http://http.developer.nvidia.com/GPUGems3/gpugems3_ch08.html */
		shadowMultiplier = ShadowContribution(sampleLightScreen, realDistanceToLight);
	}


	if(UpDotL > (-0.1f))
	{
				/*PHONG*/
		//Reflection vector
		float3 reflectionVector = normalize(reflect(lightVector, normal));

		//Camera-to-surface vector
		float3 directionToCamera = normalize(position - CameraPosition);

		//Calculate specular light 
		finalSpecularProduct += specularCoefficient * pow( saturate( dot(reflectionVector, directionToCamera)), surfaceSmoothness);
		/*End of phong*/



				/*BLINN-PHONG*/
		//float3 H = normalize( LightDirection + ViewDirection );

		////Calculate specular light 
		//finalSpecularProduct += specularCoefficient * pow( saturate( dot(normal, H)), surfaceSmoothness);
		/*End of blinn phong*/

		//Calculate diffuse light
		finalDiffuseProduct += diffuseCoefficient * (NdL * DiffuseColor.rgb);
	}


	//Essentially I save a float in the normal render target's .w channel that decides if the object should be shaded or not.
	//I do this because of how the vegatation quads are built -- they each consist of three different quads, and they all shade eachother.
	//This results in the quads looking really ass and they start flickering when the light moves and shit. Bad.
	if(recieveShadows)
	{
		return (LightIntensity*float4(finalAmbienceProduct.rgb + (finalDiffuseProduct * shadowMultiplier), (finalSpecularProduct * shadowMultiplier)));
	}
	else //Don't shade if it shouldn't recieve any shadows.
	{
		return (LightIntensity*float4(finalAmbienceProduct.rgb + finalDiffuseProduct, finalSpecularProduct));
	}
}
