cbuffer LightBufferType
{
	float4 LightPosition;
	float4 LightColor; //.w channel contains LightRadius
	//float LightRadius;
	float4 CameraPosition; //.w channel contains LightPower
	//float LightPower;
}

cbuffer PixelMatrixBufferType
{
	float4x4 InvertedView;
}

struct VertexShaderOutput
{
	float4 Position : SV_Position;
	float4 ScreenPosition : TEXCOORD0;
	float4 ViewPosition : TEXCOORD1;
	float3 ViewRay : TEXCOORD2;
};

Texture1DArray materialArray;
Texture2D textures[3]; //Color, Normal, depth. In that order
SamplerState pointSampler;

static const float CameraFarClip = 500.0f;

//////////////////////////////////////////////////
//	FUNCTIONS
//////////////////////////////////////////////////

//Decoding of GBuffer Normals
float3 DecodeNormal(float2 enc)
{
	float2 fenc = (enc*4.0f)-2.0f;
	float f = dot(fenc,fenc);
	float g = sqrt(1.0f-(f*0.25f));
	
	//float3 n;
	//n.xy = fenc*g;
	//n.z = 1.0f-(f*0.5f);

	return float3(fenc*g, 1.0f - (f*0.5f));
}

void RetrieveMaterialData(int materialID, out float Kd, out float Ks, out float surfaceSmoothness)
{
	/*
	Because the runtime does not support 1D textures, the compiler will use a 2D texture with the knowledge 
	that the y-coordinate is unimportant. Since tex1D(s, t) (DirectX HLSL) is implemented as a 2D texture lookup, 
	the compiler is free to choose the y-component in an efficient manner.
	*/

	int3 LoadingCoordinates = int3(0, materialID, 0);

	//Load all of the objects and assign them to local variables
	LoadingCoordinates.x += 1;

	Kd = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	Ks = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

	surfaceSmoothness = materialArray.Load(LoadingCoordinates);
	LoadingCoordinates.x += 1;

}

float3 ReconstructViewPositionFromDepth(float3 viewPosition, float depth)
{
	float3 viewRay = float3(viewPosition.xy * (CameraFarClip / viewPosition.z), CameraFarClip);
	return viewRay * depth;
}

float3 ReconstructWorldPositionFromDepth(float3 viewRay, float depth)
{
	return CameraPosition.xyz + (viewRay * (depth*500.0f));
}

///////////////////////////////////////////////////
//	MAIN FUNCTION
///////////////////////////////////////////////////
half4 LightPixelShader(VertexShaderOutput input) : SV_TARGET0
{
	float diffuseCoefficient, specularCoefficient, surfaceSmoothness;

	input.ScreenPosition /= input.ScreenPosition.w; //Get screen position

	float2 texCoord = 0.5f * (float2(input.ScreenPosition.x, -input.ScreenPosition.y) + 1.0f);

	float3 viewRay = normalize(input.ViewRay);

	//get normal data from the normalMap
	float4 normalData = textures[1].Sample(pointSampler, texCoord);

	int materialID = round(normalData.z * 255);
	int materialID2 = round(normalData.w * 255);

	RetrieveMaterialData(materialID, diffuseCoefficient, specularCoefficient, surfaceSmoothness);
	
	//If there's a difference between our two materials, we have to lerp!
	if(materialID != materialID2) 
	{
		float lerpVal = (textures[0].Sample(pointSampler, texCoord).w);
		float diffuseCoefficient2, specularCoefficient2, surfaceSmoothness2;

		RetrieveMaterialData(materialID2, diffuseCoefficient2, specularCoefficient2, surfaceSmoothness2);

		diffuseCoefficient = lerp(diffuseCoefficient, diffuseCoefficient2, lerpVal);
		specularCoefficient = lerp(specularCoefficient, specularCoefficient2, lerpVal);
		surfaceSmoothness = lerp(surfaceSmoothness, surfaceSmoothness2, lerpVal);
	}

	float depth = textures[2].Sample(pointSampler, texCoord);
	float3 normal = normalize(DecodeNormal(normalData.xy));
	
	float4 position = mul(float4(ReconstructViewPositionFromDepth(input.ViewPosition.xyz, depth), 1.0f), InvertedView);//float4(ReconstructWorldPositionFromDepth(viewRay, depth), 1.0f); //ReconstructPositionFromDepth(depth, input.ScreenPosition.xy);

	//surface-to-light vector
	float3 lightVector = (position-LightPosition);

	float d = length(lightVector);
	float attenuation = ((LightColor.w) / (d*d)); //(LightColor.w / (d*d)); //Slight offset to dampen the light

	//Normalize lightVector after we've used it to determine the light attenuation
	lightVector = normalize(lightVector);

	//calculate NdotL product
	float NdL = saturate(dot(normal, -lightVector));

	//compute diffuse light using NdotL product
	float3 diffuseLight = (LightColor.rgb*NdL);

	 //Blinn half angle modification for performance over correctness
	float3 h = normalize(normalize(CameraPosition - position) - lightVector);

	//compute specular light
	float specularLight = pow( saturate( dot(h, normal)), surfaceSmoothness);

	//scale final value with attenuation, take into calculation the current material of this pixel
	return attenuation*half4(diffuseCoefficient*diffuseLight, specularCoefficient*specularLight);
}

/*
vec3 DirectIllumination(vec3 P, vec3 N, vec3 lightCentre, float lightRadius, vec3 lightColour, float cutoff)
{
	float r = lightRadius;
	vec3 L = lightCentre - P;
	float distance = length(L);
	float d = max(distance - r, 0);
	L /= distance;
	
	// calculate basic attenuation
	float denom = d/r + 1;
	float attenuation = 1 / (denom*denom);
	
	// scale and bias attenuation such that:
	//   attenuation == 0 at extent of max influence
	//   attenuation == 1 when d == 0
	attenuation = (attenuation - cutoff) / (1 - cutoff);
	attenuation = max(attenuation, 0);
	
	float dot = max(dot(L, N), 0);
	return lightColour * dot * attenuation;
}
*/